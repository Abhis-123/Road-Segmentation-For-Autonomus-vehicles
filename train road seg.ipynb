{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from options.train_options import TrainOptions\n",
    "from data import CreateDataLoader , find_dataset_using_name\n",
    "from models import create_model\n",
    "from util.util import confusion_matrix, getScores, tensor2labelim, tensor2im, print_current_losses\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed Every Thing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "seed  = 20\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_opt = { 'batch_size': 2,\n",
    "                    'beta1': 0.5,\n",
    "                    'dataroot':\"./datasets/kitti/\",\n",
    "          'checkpoints_dir': './checkpoints',\n",
    "           'continue_train': False,\n",
    "                  'dataset': 'kitti',\n",
    "                    'epoch': 'latest',\n",
    "              'epoch_count': 1,\n",
    "                  'gpu_ids': 0,\n",
    "                'init_gain': 0.02,\n",
    "                'init_type': 'kaiming',\n",
    "                  'isTrain': True,                       \n",
    "                'lambda_L1': 100.0,\n",
    "                       'lr': 0.001,\n",
    "          'lr_decay_epochs': 25,\n",
    "           'lr_decay_iters': 5000000,\n",
    "                 'lr_gamma': 0.9,\n",
    "                'lr_policy': 'lambda',\n",
    "                    'model': 'roadseg',\n",
    "                 'momentum': 0.9,\n",
    "                     'name': \"exp1\",\n",
    "                   'nepoch': 1000,\n",
    "                     'norm': 'instance',\n",
    "              'num_threads': 8,\n",
    "                    'phase': 'train',\n",
    "               'print_freq': 10,\n",
    "                     \"seed\":0,\n",
    "           'serial_batches':False,\n",
    "                'useHeight':384,\n",
    "                 'useWidth':1248,\n",
    "                  \"use_sne\":False,\n",
    "                  'verbose':False,\n",
    "             'weight_decay': 0.0005,\n",
    "             \"gpu_ids\":[0]\n",
    "            \n",
    "}\n",
    "\n",
    "\n",
    "class Options:\n",
    "  def __init__(self,**kwargs):\n",
    "    self.dataroot = kwargs.get('dataroot')\n",
    "    self.batch_size = kwargs.get('batch_size')\n",
    "    self.beta1 = kwargs.get('beta1')\n",
    "    self.checkpoints_dir = kwargs.get('checkpoints_dir')\n",
    "    self.continue_train = kwargs.get('continue_train')\n",
    "    self.dataset = kwargs.get('dataset')\n",
    "    self.epoch = kwargs.get('epoch')\n",
    "    self.epoch_count = kwargs.get('epoch_count')\n",
    "    self.gpu_ids = kwargs.get('gpu_ids')\n",
    "    self.init_gain = kwargs.get('init_gain')\n",
    "    self.init_type = kwargs.get('init_type')\n",
    "    self.isTrain = kwargs.get('isTrain')\n",
    "    self.lambda_L1 = kwargs.get('lambda_L1')\n",
    "    self.lr = kwargs.get('lr')\n",
    "    self.lr_decay_iters = kwargs.get('lr_decay_iters')\n",
    "    self.lr_decay_epochs = kwargs.get('lr_decay_epochs')\n",
    "    self.lr_gamma = kwargs.get('lr_gamma')\n",
    "    self.lr_policy = kwargs.get('lr_policy')\n",
    "    self.model  = kwargs.get('model')\n",
    "    self.use_sne = kwargs.get('use_sne')\n",
    "    self.momentum = kwargs.get('momentum')\n",
    "    self.name = kwargs.get('name')\n",
    "    self.nepoch = kwargs.get('nepoch')\n",
    "    self.norm = kwargs.get('norm')\n",
    "    self.num_threads = kwargs.get('num_threads')\n",
    "    self.phase = kwargs.get('phase')\n",
    "    self.print_freq = kwargs.get('print_freq')\n",
    "    self.seed = kwargs.get('seed')\n",
    "    self.serial_batches = kwargs.get('serial_batches')\n",
    "    self.useHeight = kwargs.get('useHeight')\n",
    "    self.useWidth = kwargs.get('useWidth')\n",
    "    self.gpu_ids = kwargs.get('gpu_ids')\n",
    "    self.weight_decay = kwargs.get('weight_decay')\n",
    "    self.verbose = kwargs.get('verbose')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Options(**train_opt)\n",
    "train_opt = opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_opt.nepoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from data.base_dataset import BaseDataset\n",
    "from models.sne_model import SNE\n",
    "\n",
    "\n",
    "class kittiCalibInfo():\n",
    "    \"\"\"\n",
    "    Read calibration files in the kitti dataset,\n",
    "    we need to use the intrinsic parameter of the cam2\n",
    "    \"\"\"\n",
    "    def __init__(self, filepath):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filepath ([str]): calibration file path (AAA.txt)\n",
    "        \"\"\"\n",
    "        self.data = self._load_calib(filepath)\n",
    "\n",
    "    def get_cam_param(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            [numpy.array]: intrinsic parameter of the cam2\n",
    "        \"\"\"\n",
    "        return self.data['P2']\n",
    "\n",
    "    def _load_calib(self, filepath):\n",
    "        rawdata = self._read_calib_file(filepath)\n",
    "        data = {}\n",
    "        P0 = np.reshape(rawdata['P0'], (3,4))\n",
    "        P1 = np.reshape(rawdata['P1'], (3,4))\n",
    "        P2 = np.reshape(rawdata['P2'], (3,4))\n",
    "        P3 = np.reshape(rawdata['P3'], (3,4))\n",
    "        R0_rect = np.reshape(rawdata['R0_rect'], (3,3))\n",
    "        Tr_velo_to_cam = np.reshape(rawdata['Tr_velo_to_cam'], (3,4))\n",
    "\n",
    "        data['P0'] = P0\n",
    "        data['P1'] = P1\n",
    "        data['P2'] = P2\n",
    "        data['P3'] = P3\n",
    "        data['R0_rect'] = R0_rect\n",
    "        data['Tr_velo_to_cam'] = Tr_velo_to_cam\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _read_calib_file(self, filepath):\n",
    "        \"\"\"Read in a calibration file and parse into a dictionary.\"\"\"\n",
    "        data = {}\n",
    "\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                key, value = line.split(':', 1)\n",
    "                # The only non-float values in these files are dates, which\n",
    "                # we don't care about anyway\n",
    "                try:\n",
    "                    data[key] = np.array([float(x) for x in value.split()])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        return data\n",
    "\n",
    "\n",
    "class kittidataset(BaseDataset):\n",
    "    \"\"\"dataloader for kitti dataset\"\"\"\n",
    "    @staticmethod\n",
    "    def modify_commandline_options(parser, is_train):\n",
    "        return parser\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        self.opt = opt\n",
    "        self.batch_size = opt.batch_size\n",
    "        self.root = opt.dataroot # path for the dataset\n",
    "        self.use_sne = opt.use_sne\n",
    "        self.num_labels = 2\n",
    "        self.use_size = (opt.useWidth, opt.useHeight)\n",
    "        if self.use_sne:\n",
    "            self.sne_model = SNE()\n",
    "\n",
    "        if opt.phase == \"train\":\n",
    "            self.image_list = sorted(glob.glob(os.path.join(self.root, 'training', 'image_2', '*.png')))\n",
    "        elif opt.phase == \"val\":\n",
    "            self.image_list = sorted(glob.glob(os.path.join(self.root, 'validation', 'image_2', '*.png')))\n",
    "        else:\n",
    "            self.image_list = sorted(glob.glob(os.path.join(self.root, 'testing', 'image_2', '*.png')))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        useDir = \"/\".join(self.image_list[index].split('/')[:-2])\n",
    "        name = self.image_list[index].split('/')[-1]\n",
    "        path = os.path.join(useDir, 'image_2', name).replace(\"\\'\", '/')\n",
    "        rgb_image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "        depth_image = cv2.imread(path.replace(\"image_2\",\"depth_u16\"), cv2.IMREAD_ANYDEPTH)\n",
    "        oriHeight, oriWidth, _ = rgb_image.shape\n",
    "\n",
    "        if self.opt.phase == 'test' and self.opt.no_label:\n",
    "            # Since we have no gt label (e.g., kitti submission), we generate pseudo gt labels to\n",
    "            # avoid destroying the code architecture\n",
    "            label = np.zeros((oriHeight, oriWidth), dtype=np.uint8)\n",
    "        else:\n",
    "            # path = os.path.join(useDir, 'gt_image_2', name[:-10]+'road_'+name[-10:])\n",
    "            path = name.replace(\"image_2\",\"gt_image_2\").replace(\"um_\",\"um_lane_\")\n",
    "            # print(path)\n",
    "            label_image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "            label = np.zeros((oriHeight, oriWidth), dtype=np.uint8)\n",
    "            label[label_image[:,:,2] > 0] = 1\n",
    "\n",
    "        # resize image to enable sizes divide 32\n",
    "        rgb_image = cv2.resize(rgb_image, self.use_size)\n",
    "        label = cv2.resize(label, self.use_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # another_image will be normal when using SNE, otherwise will be depth\n",
    "        if self.use_sne:\n",
    "            calib = kittiCalibInfo(os.path.join(useDir, 'calib', name[:-4]+'.txt'))\n",
    "            camParam = torch.tensor(calib.get_cam_param(), dtype=torch.float32)\n",
    "            normal = self.sne_model(torch.tensor(depth_image.astype(np.float32)/1000), camParam)\n",
    "            another_image = normal.cpu().numpy()\n",
    "            another_image = np.transpose(another_image, [1, 2, 0])\n",
    "            another_image = cv2.resize(another_image, self.use_size)\n",
    "        else:\n",
    "            another_image = depth_image.astype(np.float32)/65535\n",
    "            another_image = cv2.resize(another_image, self.use_size)\n",
    "            another_image = another_image[:,:,np.newaxis]\n",
    "\n",
    "        label[label > 0] = 1\n",
    "        rgb_image = rgb_image.astype(np.float32) / 255\n",
    "\n",
    "        rgb_image = transforms.ToTensor()(rgb_image)\n",
    "        another_image = transforms.ToTensor()(another_image)\n",
    "\n",
    "        label = torch.from_numpy(label)\n",
    "        label = label.type(torch.LongTensor)\n",
    "\n",
    "        # return a dictionary containing useful information\n",
    "        # input rgb images, another images and labels for training;\n",
    "        # 'path': image name for saving predictions\n",
    "        # 'oriSize': original image size for evaluating and saving predictions\n",
    "        return {'rgb_image': rgb_image, 'another_image': another_image, 'label': label,\n",
    "                'path': name, 'oriSize': (oriWidth, oriHeight)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def name(self):\n",
    "        return 'kitti'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = kittidataset()\n",
    "train_opt.dataroot = \"D:\\Project Bipot\\SNE-RoadSeg\\datasets\\kitti\"\n",
    "train_opt.phase = 'train'\n",
    "dataset.initialize(train_opt)\n",
    "result = dataset.__getitem__(0)\n",
    "dataset.image_list = dataset.image_list[:24]\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=1,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_opt.gpu_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\Abhishek pandir/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:12<00:00, 3.74MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "model [RoadSegModel] was created\n",
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): RoadSeg(\n",
      "    (encoder_another_conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (encoder_another_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (encoder_another_relu): ReLU(inplace=True)\n",
      "    (encoder_another_maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (encoder_another_layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_another_layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_another_layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_another_layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_rgb_conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (encoder_rgb_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (encoder_rgb_relu): ReLU(inplace=True)\n",
      "    (encoder_rgb_maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (encoder_rgb_layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_rgb_layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_rgb_layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_rgb_layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (conv1_1): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv2_1): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv3_1): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv4_1): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1_2): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv2_2): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv3_2): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1_3): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv2_3): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1_4): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up2_0): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up2_1): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up2_2): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up2_3): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up3_0): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up3_1): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up3_2): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up4_0): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up4_1): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up5_0): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (final): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network RoadSeg] Total number of parameters : 28.402 M\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_opt = opt\n",
    "train_opt.continue_train = False\n",
    "train_opt.isTrain = True\n",
    "train_opt.verbose = True\n",
    "model = create_model(train_opt, dataset)\n",
    "model.setup(train_opt)\n",
    "total_steps = 0\n",
    "tfcount = 0\n",
    "F_score_max = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    for epoch in range(train_opt.epoch_count, train_opt.nepoch + 1):\n",
    "        ### Training on the training set ###\n",
    "        model.train()\n",
    "        epoch_start_time = time.time()\n",
    "        iter_data_time = time.time()\n",
    "        epoch_iter = 0\n",
    "        train_loss_iter = []\n",
    "        for i, data in enumerate(dataloader):\n",
    "            iter_start_time = time.time()\n",
    "            if total_steps % train_opt.print_freq == 0:\n",
    "                t_data = iter_start_time - iter_data_time\n",
    "            total_steps += train_opt.batch_size\n",
    "            epoch_iter += train_opt.batch_size\n",
    "            model.set_input(data)\n",
    "            model.optimize_parameters()\n",
    "\n",
    "            if total_steps % train_opt.print_freq == 0:\n",
    "                tfcount = tfcount + 1\n",
    "                losses = model.get_current_losses()\n",
    "                train_loss_iter.append(losses[\"segmentation\"])\n",
    "                t = (time.time() - iter_start_time) / train_opt.batch_size\n",
    "                print_current_losses(epoch, epoch_iter, losses, t, t_data)\n",
    "                # There are several whole_loss values shown in tensorboard in one epoch,\n",
    "                # to help better see the optimization phase\n",
    "                writer.add_scalar('train/whole_loss', losses[\"segmentation\"], tfcount)\n",
    "\n",
    "            iter_data_time = time.time()\n",
    "\n",
    "        mean_loss = np.mean(train_loss_iter)\n",
    "        # One average training loss value in tensorboard in one epoch\n",
    "        writer.add_scalar('train/mean_loss', mean_loss, epoch)\n",
    "\n",
    "        palet_file = 'datasets/palette.txt'\n",
    "        impalette = list(np.genfromtxt(palet_file,dtype=np.uint8).reshape(3*256))\n",
    "        tempDict = model.get_current_visuals()\n",
    "        rgb = tensor2im(tempDict['rgb_image'])\n",
    "        if train_opt.use_sne:\n",
    "            another = tensor2im((tempDict['another_image']+1)/2)    # color normal images\n",
    "        else:\n",
    "            another = tensor2im(tempDict['another_image'])\n",
    "        label = tensor2labelim(tempDict['label'], impalette)\n",
    "        output = tensor2labelim(tempDict['output'], impalette)\n",
    "        image_numpy = np.concatenate((rgb, another, label, output), axis=1)\n",
    "        image_numpy = image_numpy.astype(np.float64) / 255\n",
    "        writer.add_image('Epoch' + str(epoch), image_numpy, dataformats='HWC')  # show training images in tensorboard\n",
    "\n",
    "        print('End of epoch %d / %d \\t Time Taken: %d sec' %   (epoch, train_opt.nepoch, time.time() - epoch_start_time))\n",
    "        model.update_learning_rate()\n",
    "\n",
    "        # ### Evaluation on the validation set ###\n",
    "        # model.eval()\n",
    "        # valid_loss_iter = []\n",
    "        # epoch_iter = 0\n",
    "        # conf_mat = np.zeros((valid_dataset.dataset.num_labels, valid_dataset.dataset.num_labels), dtype=np.float)\n",
    "        # with torch.no_grad():\n",
    "        #     for i, data in enumerate(valid_dataset):\n",
    "        #         model.set_input(data)\n",
    "        #         model.forward()\n",
    "        #         model.get_loss()\n",
    "        #         epoch_iter += valid_opt.batch_size\n",
    "        #         gt = model.label.cpu().int().numpy()\n",
    "        #         _, pred = torch.max(model.output.data.cpu(), 1)\n",
    "        #         pred = pred.float().detach().int().numpy()\n",
    "\n",
    "        #         # Resize images to the original size for evaluation\n",
    "        #         image_size = model.get_image_oriSize()\n",
    "        #         oriSize = (image_size[0].item(), image_size[1].item())\n",
    "        #         gt = np.expand_dims(cv2.resize(np.squeeze(gt, axis=0), oriSize, interpolation=cv2.INTER_NEAREST), axis=0)\n",
    "        #         pred = np.expand_dims(cv2.resize(np.squeeze(pred, axis=0), oriSize, interpolation=cv2.INTER_NEAREST), axis=0)\n",
    "\n",
    "        #         conf_mat += confusion_matrix(gt, pred, valid_dataset.dataset.num_labels)\n",
    "        #         losses = model.get_current_losses()\n",
    "        #         valid_loss_iter.append(model.loss_segmentation)\n",
    "        #         print('valid epoch {0:}, iters: {1:}/{2:} '.format(epoch, epoch_iter, len(valid_dataset) * valid_opt.batch_size), end='\\r')\n",
    "\n",
    "        # avg_valid_loss = torch.mean(torch.stack(valid_loss_iter))\n",
    "        # globalacc, pre, recall, F_score, iou = getScores(conf_mat)\n",
    "\n",
    "        # # Record performance on the validation set\n",
    "        # writer.add_scalar('valid/loss', avg_valid_loss, epoch)\n",
    "        # writer.add_scalar('valid/global_acc', globalacc, epoch)\n",
    "        # writer.add_scalar('valid/pre', pre, epoch)\n",
    "        # writer.add_scalar('valid/recall', recall, epoch)\n",
    "        # writer.add_scalar('valid/F_score', F_score, epoch)\n",
    "        # writer.add_scalar('valid/iou', iou, epoch)\n",
    "\n",
    "        # # Save the best model according to the F-score, and record corresponding epoch number in tensorboard\n",
    "        # if F_score > F_score_max:\n",
    "        #     print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))\n",
    "        #     model.save_networks('best')\n",
    "        #     F_score_max = F_score\n",
    "        #     writer.add_text('best model', str(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = kittidataset()\n",
    "train_opt.dataroot = \"D:\\Project Bipot\\SNE-RoadSeg\\datasets\\kitti\"\n",
    "train_opt.phase = 'train'\n",
    "dataset.initialize(train_opt)\n",
    "result = dataset.__getitem__(0)\n",
    "dataset.image_list = dataset.image_list[:24]\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=1,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [kitti] was created\n",
      "#training images = 289\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from options.train_options import TrainOptions\n",
    "from data import CreateDataLoader\n",
    "from models import create_model\n",
    "from util.util import confusion_matrix, getScores, tensor2labelim, tensor2im, print_current_losses\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import cv2\n",
    "from tensorboardX import SummaryWriter\n",
    "if True:    \n",
    "    train_opt = opt\n",
    "\n",
    "    np.random.seed(train_opt.seed)\n",
    "    random.seed(train_opt.seed)\n",
    "    torch.manual_seed(train_opt.seed)\n",
    "    torch.cuda.manual_seed(train_opt.seed)\n",
    "\n",
    "    train_opt.nepoch = 5\n",
    "    train_opt.phase = 'train'\n",
    "    train_opt.batch_size =1\n",
    "    train_data_loader = CreateDataLoader(train_opt)\n",
    "    train_dataset = train_data_loader.load_data()\n",
    "    train_dataset_size = len(train_data_loader)\n",
    "    print('#training images = %d' % train_dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with pretrained\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "model [RoadSegModel] was created\n",
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): RoadSeg(\n",
      "    (encoder_another_conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (encoder_another_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (encoder_another_relu): ReLU(inplace=True)\n",
      "    (encoder_another_maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (encoder_another_layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_another_layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_another_layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_another_layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_rgb_conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (encoder_rgb_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (encoder_rgb_relu): ReLU(inplace=True)\n",
      "    (encoder_rgb_maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (encoder_rgb_layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_rgb_layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_rgb_layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_rgb_layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (conv1_1): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv2_1): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv3_1): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv4_1): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1_2): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv2_2): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv3_2): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1_3): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv2_3): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1_4): conv_block_nested(\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up2_0): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up2_1): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up2_2): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up2_3): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up3_0): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up3_1): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up3_2): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up4_0): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up4_1): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (up5_0): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (final): upsample_layer(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network RoadSeg] Total number of parameters : 28.402 M\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    model = create_model(train_opt, train_dataset.dataset)\n",
    "    model.setup(train_opt)\n",
    "    total_steps = 0\n",
    "    tfcount = 0\n",
    "    F_score_max = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 3.00 GiB total capacity; 1.87 GiB already allocated; 3.91 MiB free; 1.92 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-85397ff604c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mepoch_iter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtotal_steps\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtrain_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Project Bipot\\SNE-RoadSeg\\models\\roadseg_model.py\u001b[0m in \u001b[0;36moptimize_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moptimize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_RoadSeg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Project Bipot\\SNE-RoadSeg\\models\\roadseg_model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetRoadSeg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrgb_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manother_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Project Bipot\\SNE-RoadSeg\\models\\networks.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, rgb, another)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mrgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_rgb_conv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[0mrgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_rgb_bn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mrgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_rgb_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 439\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 3.00 GiB total capacity; 1.87 GiB already allocated; 3.91 MiB free; 1.92 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    for epoch in range(train_opt.epoch_count, train_opt.nepoch + 1):\n",
    "        ### Training on the training set ###\n",
    "        model.train()\n",
    "        epoch_start_time = time.time()\n",
    "        iter_data_time = time.time()\n",
    "        epoch_iter = 0\n",
    "        train_loss_iter = []\n",
    "        for i, data in enumerate(dataloader):\n",
    "            iter_start_time = time.time()\n",
    "            if total_steps % train_opt.print_freq == 0:\n",
    "                t_data = iter_start_time - iter_data_time\n",
    "            total_steps += train_opt.batch_size\n",
    "            epoch_iter += train_opt.batch_size\n",
    "            model.set_input(data)\n",
    "            model.optimize_parameters()\n",
    "\n",
    "            if total_steps % train_opt.print_freq == 0:\n",
    "                tfcount = tfcount + 1\n",
    "                losses = model.get_current_losses()\n",
    "                train_loss_iter.append(losses[\"segmentation\"])\n",
    "                t = (time.time() - iter_start_time) / train_opt.batch_size\n",
    "                print_current_losses(epoch, epoch_iter, losses, t, t_data)\n",
    "                # There are several whole_loss values shown in tensorboard in one epoch,\n",
    "                # to help better see the optimization phase\n",
    "                writer.add_scalar('train/whole_loss', losses[\"segmentation\"], tfcount)\n",
    "\n",
    "            iter_data_time = time.time()\n",
    "\n",
    "        mean_loss = np.mean(train_loss_iter)\n",
    "        # One average training loss value in tensorboard in one epoch\n",
    "        writer.add_scalar('train/mean_loss', mean_loss, epoch)\n",
    "\n",
    "        palet_file = 'datasets/palette.txt'\n",
    "        impalette = list(np.genfromtxt(palet_file,dtype=np.uint8).reshape(3*256))\n",
    "        tempDict = model.get_current_visuals()\n",
    "        rgb = tensor2im(tempDict['rgb_image'])\n",
    "        if train_opt.use_sne:\n",
    "            another = tensor2im((tempDict['another_image']+1)/2)    # color normal images\n",
    "        else:\n",
    "            another = tensor2im(tempDict['another_image'])\n",
    "        label = tensor2labelim(tempDict['label'], impalette)\n",
    "        output = tensor2labelim(tempDict['output'], impalette)\n",
    "        image_numpy = np.concatenate((rgb, another, label, output), axis=1)\n",
    "        image_numpy = image_numpy.astype(np.float64) / 255\n",
    "        writer.add_image('Epoch' + str(epoch), image_numpy, dataformats='HWC')  # show training images in tensorboard\n",
    "\n",
    "        print('End of epoch %d / %d \\t Time Taken: %d sec' %   (epoch, train_opt.nepoch, time.time() - epoch_start_time))\n",
    "        model.update_learning_rate()\n",
    "\n",
    "        # ### Evaluation on the validation set ###\n",
    "        # model.eval()\n",
    "        # valid_loss_iter = []\n",
    "        # epoch_iter = 0\n",
    "        # conf_mat = np.zeros((valid_dataset.dataset.num_labels, valid_dataset.dataset.num_labels), dtype=np.float)\n",
    "        # with torch.no_grad():\n",
    "        #     for i, data in enumerate(valid_dataset):\n",
    "        #         model.set_input(data)\n",
    "        #         model.forward()\n",
    "        #         model.get_loss()\n",
    "        #         epoch_iter += valid_opt.batch_size\n",
    "        #         gt = model.label.cpu().int().numpy()\n",
    "        #         _, pred = torch.max(model.output.data.cpu(), 1)\n",
    "        #         pred = pred.float().detach().int().numpy()\n",
    "\n",
    "        #         # Resize images to the original size for evaluation\n",
    "        #         image_size = model.get_image_oriSize()\n",
    "        #         oriSize = (image_size[0].item(), image_size[1].item())\n",
    "        #         gt = np.expand_dims(cv2.resize(np.squeeze(gt, axis=0), oriSize, interpolation=cv2.INTER_NEAREST), axis=0)\n",
    "        #         pred = np.expand_dims(cv2.resize(np.squeeze(pred, axis=0), oriSize, interpolation=cv2.INTER_NEAREST), axis=0)\n",
    "\n",
    "        #         conf_mat += confusion_matrix(gt, pred, valid_dataset.dataset.num_labels)\n",
    "        #         losses = model.get_current_losses()\n",
    "        #         valid_loss_iter.append(model.loss_segmentation)\n",
    "        #         print('valid epoch {0:}, iters: {1:}/{2:} '.format(epoch, epoch_iter, len(valid_dataset) * valid_opt.batch_size), end='\\r')\n",
    "\n",
    "        # avg_valid_loss = torch.mean(torch.stack(valid_loss_iter))\n",
    "        # globalacc, pre, recall, F_score, iou = getScores(conf_mat)\n",
    "\n",
    "        # # Record performance on the validation set\n",
    "        # writer.add_scalar('valid/loss', avg_valid_loss, epoch)\n",
    "        # writer.add_scalar('valid/global_acc', globalacc, epoch)\n",
    "        # writer.add_scalar('valid/pre', pre, epoch)\n",
    "        # writer.add_scalar('valid/recall', recall, epoch)\n",
    "        # writer.add_scalar('valid/F_score', F_score, epoch)\n",
    "        # writer.add_scalar('valid/iou', iou, epoch)\n",
    "\n",
    "        # # Save the best model according to the F-score, and record corresponding epoch number in tensorboard\n",
    "        # if F_score > F_score_max:\n",
    "        #     print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))\n",
    "        #     model.save_networks('best')\n",
    "        #     F_score_max = F_score\n",
    "        #     writer.add_text('best model', str(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
